from fastapi import FastAPI, UploadFile, File
from fastapi.responses import JSONResponse
from ultralytics import YOLO
from PIL import Image
import torch
import numpy as np
import cv2
import albumentations as A
from albumentations.pytorch import ToTensorV2
import segmentation_models_pytorch as smp
import io, time, traceback, asyncio

app = FastAPI(title="YOLO + DeepLabV3+ Unified API")

# =========================================================
# Busy/Lock (ÎèôÏãú ÏöîÏ≤≠ Î∞©ÏßÄ)
# =========================================================
busy_lock = asyncio.Lock()
is_busy = False

@app.get("/status")
def status():
    return {"status": "busy" if is_busy else "idle"}

# =========================================================
# Í≥µÌÜµ: ÏóÖÎ°úÎìú ÌååÏùº -> Ïù¥ÎØ∏ÏßÄ ÎîîÏΩîÎî© (Ìï≠ÏÉÅ np.ndarray Î≥¥Ïû•)
#   - Î∞òÌôò: rgb(np.uint8 HWC), bgr(np.uint8 HWC)
# =========================================================
def decode_upload_image(image_bytes: bytes):
    if not image_bytes or len(image_bytes) < 10:
        raise ValueError("ÏóÖÎ°úÎìúÎêú ÌååÏùºÏù¥ ÎπÑÏñ¥ÏûàÍ±∞ÎÇò ÎÑàÎ¨¥ ÏûëÏäµÎãàÎã§.")

    try:
        pil_img = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    except Exception as e:
        raise ValueError(f"PIL Ïù¥ÎØ∏ÏßÄ Ïò§Ìîà Ïã§Ìå®: {e}")

    rgb = np.array(pil_img, dtype=np.uint8)

    if not isinstance(rgb, np.ndarray):
        raise ValueError("RGB Î≥ÄÌôò Ïã§Ìå®: numpy array ÏïÑÎãò")
    if rgb.ndim != 3 or rgb.shape[2] != 3:
        raise ValueError(f"RGB shape Ïù¥ÏÉÅ: {rgb.shape}")

    # contiguous Î≥¥Ïû•
    rgb = np.ascontiguousarray(rgb)

    # ‚úÖ OpenCV ÏÇ¨Ïö© Í∏àÏßÄ ‚Üí numpy slicing
    bgr = rgb[:, :, ::-1].copy()

    return rgb, bgr

# =========================================================
# YOLO (lazy load + fuse 1Ìöå)
# =========================================================
YOLO_MODEL_PATH = "best2.pt"
_yolo_model = None

def get_yolo():
    global _yolo_model
    if _yolo_model is None:
        print("üöÄ Loading YOLO model...")
        m = YOLO(YOLO_MODEL_PATH)
        # fuseÎäî ÎêòÎ©¥ ÌïòÍ≥†, Ïïà ÎêòÎ©¥ Ìå®Ïä§(ÌôòÍ≤ΩÏóê Îî∞Îùº ÏòàÏô∏ Í∞ÄÎä•)
        try:
            m.fuse()
        except Exception as e:
            print(f"‚ö†Ô∏è YOLO fuse skipped: {e}")
        _yolo_model = m
        print("‚úÖ YOLO model loaded")
    return _yolo_model

# =========================================================
# DeepLabV3+ Î™®Îç∏ Î°úÎìú
# =========================================================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
DLAB_MODEL_PATH = "best_dlab30.pth"

def load_dlab_model():
    model = smp.DeepLabV3Plus(
        encoder_name="resnet34",
        encoder_weights="imagenet",
        in_channels=3,
        classes=1
    )
    model.load_state_dict(torch.load(DLAB_MODEL_PATH, map_location=DEVICE))
    model.to(DEVICE)
    model.eval()
    return model

dlab_model = load_dlab_model()
print("‚úÖ DeepLabV3+ model loaded")

# DeepLab Ï†ÑÏ≤òÎ¶¨
val_tf = A.Compose([
    A.Resize(512, 512),
    A.Normalize(mean=(0.485, 0.456, 0.406),
                std=(0.229, 0.224, 0.225)),
    ToTensorV2(),
])

def preprocess(image_rgb_uint8: np.ndarray):
    aug = val_tf(image=image_rgb_uint8)
    return aug["image"].unsqueeze(0).to(DEVICE)

def predict_mask(image_tensor):
    with torch.no_grad():
        pred = dlab_model(image_tensor)
        pred_mask = torch.sigmoid(pred).squeeze().cpu().numpy()
        return (pred_mask > 0.38).astype(np.uint8)

def calculate_area(pred_mask, orig_shape_hw):
    orig_h, orig_w = orig_shape_hw
    pred_mask_resized = cv2.resize(pred_mask, (orig_w, orig_h), interpolation=cv2.INTER_NEAREST)
    area_pixels = int(np.sum(pred_mask_resized))
    total_pixels = int(orig_h * orig_w)
    area_ratio = (area_pixels / total_pixels) * 100 if total_pixels > 0 else 0.0
    area_cm2 = area_pixels * 0.0001  # Í∞ÄÏ†ï
    return area_pixels, area_ratio, area_cm2

# =========================================================
# YOLO /detect endpoint
# =========================================================
@app.post("/detect")
async def detect_objects(file: UploadFile = File(...)):
    global is_busy
    async with busy_lock:
        try:
            is_busy = True

            image_bytes = await file.read()
            # ÎîîÏΩîÎî©: rgb/bgr Îëò Îã§ ÌôïÎ≥¥ (YOLOÎäî bgrÎ°ú ÎÑ£ÎäîÍ≤å Í∞ÄÏû• ÏïàÏ†Ñ)
            rgb, bgr = decode_upload_image(image_bytes)

            # ÎîîÎ≤ÑÍ∑∏ (Î°úÍ∑∏Ïóê Ï∞çÌòÄÏÑú ÌÉÄÏûÖ ÌôïÏù∏ Í∞ÄÎä•)
            print(f"DEBUG upload={file.filename} bytes={len(image_bytes)} "
                  f"bgr.shape={bgr.shape} dtype={bgr.dtype} contiguous={bgr.flags['C_CONTIGUOUS']}")

            yolo = get_yolo()

            start_time = time.time()
            # ‚úÖ UltralyticsÎäî predictÎ°ú Í≥†Ï†ï
            results = yolo.predict(
                source=bgr,     # numpy.ndarray (H,W,3) uint8
                imgsz=640,
                conf=0.3,
                verbose=False
            )
            inference_time = round((time.time() - start_time) * 1000, 2)

            predictions = []
            object_count = 0

            if results and len(results) > 0 and results[0].boxes is not None:
                for box in results[0].boxes:
                    cls_id = int(box.cls[0])
                    conf = float(box.conf[0])
                    x1, y1, x2, y2 = box.xyxy[0].tolist()

                    object_count += 1
                    predictions.append({
                        "class_id": cls_id,
                        "confidence": round(conf * 100, 2),
                        "box": [round(x1, 2), round(y1, 2), round(x2, 2), round(y2, 2)]
                    })

            return {
                "filename": file.filename,
                "object_count": object_count,
                "inference_time_ms": inference_time,
                "predictions": predictions
            }

        except Exception as e:
            traceback.print_exc()
            return JSONResponse(status_code=500, content={"error": str(e)})

        finally:
            is_busy = False

# =========================================================
# DeepLab /segment endpoint
# =========================================================
@app.post("/segment")
async def segment_area(file: UploadFile = File(...)):
    try:
        start_time = time.time()

        image_bytes = await file.read()
        rgb, _ = decode_upload_image(image_bytes)
        orig_shape = rgb.shape[:2]  # (h, w)

        image_t = preprocess(rgb)
        pred_mask = predict_mask(image_t)

        area_pixels, area_ratio, area_cm2 = calculate_area(pred_mask, orig_shape)
        inference_time_ms = round((time.time() - start_time) * 1000, 2)

        return {
            "model": "DeepLabV3+",
            "filename": file.filename,
            "area_count": int(area_pixels),
            "area_ratio_percent": round(area_ratio, 2),
            "area_cm2_assumed": round(area_cm2, 2),
            "inference_time_ms": inference_time_ms
        }

    except Exception as e:
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"error": str(e)})
